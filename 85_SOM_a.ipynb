{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "85 SOM a",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YongchangHu/Books/blob/master/85_SOM_a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLLULptMdRcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For plotting the images\n",
        "from matplotlib import pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sys, os,cv2\n",
        "from sklearn.utils import shuffle\n",
        "from scipy.misc import imread,imresize\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from skimage.transform import resize\n",
        "from imgaug import augmenters as iaa\n",
        "import imgaug as ia\n",
        "from skimage.color import rgba2rgb\n",
        "\n",
        "old_v = tf.logging.get_verbosity()\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "plt.style.use('seaborn-white')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "np.random.seed(6278)\n",
        "tf.set_random_seed(6728)\n",
        "ia.seed(6278)\n",
        "\n",
        "# SOM as layer\n",
        "class SOM_Layer(): \n",
        "\n",
        "    def __init__(self,m,n,dim,learning_rate_som = 0.04,radius_factor = 1.1,gaussian_std=0.5):\n",
        "        \n",
        "        self.m = m\n",
        "        self.n = n\n",
        "        self.dim = dim\n",
        "        self.gaussian_std = gaussian_std\n",
        "        self.map = tf.Variable(tf.random_uniform(shape=[m*n,dim],minval=0.0,maxval=1.0,seed=2))\n",
        "\n",
        "        self.location_vects = tf.constant(np.array(list(self._neuron_locations(m, n))))\n",
        "        self.alpha = learning_rate_som\n",
        "        self.sigma = max(m,n)*1.1\n",
        "\n",
        "    def _neuron_locations(self, m, n):\n",
        "        \"\"\"\n",
        "        Yields one by one the 2-D locations of the individual neurons in the SOM.\n",
        "        \"\"\"\n",
        "        # Nested iterations over both dimensions to generate all 2-D locations in the map\n",
        "        for i in range(m):\n",
        "            for j in range(n):\n",
        "                yield np.array([i, j])\n",
        "\n",
        "    def getmap(self): return self.map\n",
        "    def getlocation(self): return self.bmu_locs\n",
        "\n",
        "    def feedforward(self,input):\n",
        "    \n",
        "        self.input = input\n",
        "        self.squared_distance = tf.reduce_sum(tf.pow(tf.subtract(tf.expand_dims(self.map, axis=0),tf.expand_dims(self.input, axis=1)), 2), 2)\n",
        "        self.bmu_indices = tf.argmin(self.squared_distance, axis=1)\n",
        "        self.bmu_locs = tf.reshape(tf.gather(self.location_vects, self.bmu_indices), [-1, 2])\n",
        "\n",
        "    def backprop(self,iter,num_epoch):\n",
        "\n",
        "        # Update the weigths \n",
        "        radius = tf.subtract(self.sigma,\n",
        "                                tf.multiply(iter,\n",
        "                                            tf.divide(tf.cast(tf.subtract(self.alpha, 1),tf.float32),\n",
        "                                                    tf.cast(tf.subtract(num_epoch, 1),tf.float32))))\n",
        "\n",
        "        alpha = tf.subtract(self.alpha,\n",
        "                            tf.multiply(iter,\n",
        "                                            tf.divide(tf.cast(tf.subtract(self.alpha, 1),tf.float32),\n",
        "                                                      tf.cast(tf.subtract(num_epoch, 1),tf.float32))))\n",
        "\n",
        "        self.bmu_distance_squares = tf.reduce_sum(\n",
        "                tf.pow(tf.subtract(\n",
        "                    tf.expand_dims(self.location_vects, axis=0),\n",
        "                    tf.expand_dims(self.bmu_locs, axis=1)), 2), \n",
        "            2)\n",
        "\n",
        "        self.neighbourhood_func = tf.exp(tf.divide(tf.negative(tf.cast(\n",
        "                self.bmu_distance_squares, \"float32\")), tf.multiply(\n",
        "                tf.square(tf.multiply(radius, self.gaussian_std)), 2)))\n",
        "\n",
        "        self.learning_rate_op = tf.multiply(self.neighbourhood_func, alpha)\n",
        "        \n",
        "        self.numerator = tf.reduce_sum(\n",
        "            tf.multiply(tf.expand_dims(self.learning_rate_op, axis=-1),\n",
        "            tf.expand_dims(self.input, axis=1)), axis=0)\n",
        "\n",
        "        self.denominator = tf.expand_dims(\n",
        "            tf.reduce_sum(self.learning_rate_op,axis=0) + float(1e-20), axis=-1)\n",
        "\n",
        "        self.new_weights = tf.div(self.numerator, self.denominator)\n",
        "        self.update = tf.assign(self.map, self.new_weights)\n",
        "\n",
        "        return self.update\n",
        "\n",
        "# data\n",
        "mnist = input_data.read_data_sets('../../Dataset/MNIST/', one_hot=True)\n",
        "train, test = tf.keras.datasets.mnist.load_data()\n",
        "x_data, train_label, y_data, test_label = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
        "\n",
        "train_batch = x_data/1.0\n",
        "test_batch = y_data/1.0\n",
        "train_batch = train_batch[:100,:]\n",
        "train_label = train_label[:100,:]\n",
        "test_batch = test_batch[:50,:]\n",
        "test_label = test_label[:50,:]\n",
        "\n",
        "# print out the data shape\n",
        "print(train_batch.shape)\n",
        "print(train_label.shape)\n",
        "print(test_batch.shape)\n",
        "print(test_label.shape)\n",
        "\n",
        "# hyper parameter\n",
        "map_width_height  = 30\n",
        "map_dim = 784\n",
        "num_epoch = 100\n",
        "batch_size = 100\n",
        "\n",
        "# class\n",
        "SOM_layer = SOM_Layer(map_width_height,map_width_height,map_dim,\n",
        "learning_rate_som=0.8,radius_factor=1.1,gaussian_std = 0.08)\n",
        "\n",
        "# create the graph\n",
        "x = tf.placeholder(shape=[None,map_dim],dtype=tf.float32)\n",
        "current_iter = tf.placeholder(shape=[],dtype=tf.float32)\n",
        "\n",
        "# graph\n",
        "SOM_layer.feedforward(x)\n",
        "map_update=SOM_layer.backprop(current_iter,num_epoch)\n",
        "\n",
        "# session\n",
        "with tf.Session() as sess: \n",
        "\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # start the training\n",
        "    for iter in range(num_epoch):\n",
        "        for current_train_index in range(0,len(test_batch),batch_size):\n",
        "            currren_train = train_batch[current_train_index:current_train_index+batch_size]\n",
        "            sess_results = sess.run(map_update,feed_dict={x:currren_train,current_iter:iter})\n",
        "            print('Current Iter: ',iter,' Current Train Index: ',current_train_index,' Current SUM of updated Values: ',sess_results.sum(),end='\\r' )\n",
        "        print('\\n-----------------------')\n",
        "\n",
        "    # after training is done get the cloest vector\n",
        "    locations = sess.run(SOM_layer.getlocation(),feed_dict={x:train_batch})\n",
        "    x1 = locations[:,0]; y1 = locations[:,1]\n",
        "    index = [ np.where(r==1)[0][0] for r in train_label ]\n",
        "    index = list(map(str, index))\n",
        "\n",
        "    ## Plots: 1) Train 2) Test+Train ###\n",
        "    plt.figure(1, figsize=(12,6))\n",
        "    plt.subplot(121)\n",
        "    plt.scatter(x1,y1)\n",
        "    # Just adding text\n",
        "    for i, m in enumerate(locations):\n",
        "        plt.text( m[0], m[1],index[i], ha='center', va='center', \n",
        "        bbox=dict(facecolor='white', alpha=0.5, lw=0))\n",
        "    plt.title('Train MNIST 100')\n",
        "\n",
        "    locations2 = sess.run(SOM_layer.getlocation(),feed_dict={x:test_batch})\n",
        "    x2 = locations2[:,0]; y2 = locations2[:,1]\n",
        "    index2 = [ np.where(r==1)[0][0] for r in test_label ]\n",
        "    index2 = list(map(str, index2))\n",
        "\n",
        "    plt.subplot(122)\n",
        "    # Plot 2: Training + Testing\n",
        "    plt.scatter(x1,y1)\n",
        "    # Just adding text\n",
        "    for i, m in enumerate(locations):\n",
        "        plt.text( m[0], m[1],index[i], ha='center', va='center', bbox=dict(facecolor='white', alpha=0.5, lw=0))\n",
        "\n",
        "    plt.scatter(x2,y2)\n",
        "    # Just adding text\n",
        "    for i, m in enumerate(locations2):\n",
        "        plt.text( m[0], m[1],index2[i], ha='center', va='center', bbox=dict(facecolor='red', alpha=0.5, lw=0))\n",
        "    plt.title('Test MNIST 10 + Train MNIST 100')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# -- end code --"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}